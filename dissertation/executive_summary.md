# Executive Summary

This dissertation presents a large-scale, metadata-driven fairness audit in the adult-content domain, analysing **535,236** videos from a major platform. We assess representational and allocative harms with a focus on **Black women**, combining temporal, engagement and linguistic harm analyses with model-based fairness evaluation and mitigation.


## Key findings

## Implications for industry
- **Fairness-aware ranking:** Construct a Pareto frontier of accuracy vs fairness to constrain disparities while preserving engagement.
- **Taxonomy-guided moderation:** Use category-specific over/under-representation and harm RRs for targeted, auditable interventions.
- **Monitoring at scale:** Use uncertainty-aware metrics (bootstrap CIs, effect sizes) as a continuous fairness monitor.

## Future research
- **Causal identification:** Move beyond correlational gaps via causal graphs and interventional tests.
- **Intersectional constraints:** Evaluate differential and counterfactual-individual fairness under domain-specific utility constraints.

*Notes:* Category totals can exceed N due to **multi-label** assignment. Some titles are not in English; tags/categories (MPU) preserve interpretable semantics. Years are integers; ratings shown with one decimal place; other metrics rounded sensibly.
